{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3318,
     "status": "ok",
     "timestamp": 1768523521042,
     "user": {
      "displayName": "Arthur Santos",
      "userId": "03203688616351214794"
     },
     "user_tz": 180
    },
    "id": "BDyWEisDm6Es",
    "outputId": "729b6db5-f35c-4613-f376-79304f9d1f27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-AKFlpOqW5i"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Definir caminhos relativos\n",
    "SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "PASTA_BASE = os.path.dirname(SCRIPT_DIR)  # Subir um nível para a pasta raiz\n",
    "\n",
    "PASTA_ENTRADA = os.path.join(PASTA_BASE, \"dados_entrada\")\n",
    "PASTA_SAIDA = os.path.join(PASTA_BASE, \"dados_saida\")\n",
    "PASTA_MODELOS = os.path.join(PASTA_BASE, \"modelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1768523521381,
     "user": {
      "displayName": "Arthur Santos",
      "userId": "03203688616351214794"
     },
     "user_tz": 180
    },
    "id": "AzaFGLaum8a1",
    "outputId": "0359b8f2-065a-4e05-de9f-eaeba303ce55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as variáveis de configuração foram definidas em uma única célula.\n"
     ]
    }
   ],
   "source": [
    "ARQUIVO_TREINO = os.path.join(PASTA_ENTRADA, \"arquivo.csv\")\n",
    "COLUNA_TEXTO = \"coluna_x\"\n",
    "COLUNA_LABEL = \"coluna_y\" # 1 = X, 0 = não X\n",
    "\n",
    "# Dados para classificação em lote\n",
    "EXTENSOES_VALIDAS = (\".csv\", \".xlsx\")\n",
    "\n",
    "\n",
    "# Limiares para revisão humana\n",
    "LIMIAR_CONFIANTE = 0.90  # Ajustado de 0.80\n",
    "LIMIAR_DUVIDOSO = 0.40   # Ajustado de 0.50\n",
    "\n",
    "\n",
    "# Nomes dos artefatos\n",
    "ARQ_VECTORIZER = os.path.join(PASTA_MODELOS, \"vectorizer.joblib\")\n",
    "ARQ_MODEL = os.path.join(PASTA_MODELOS, \"model.joblib\")\n",
    "\n",
    "print(\"Todas as variáveis de configuração foram definidas em uma única célula.\")\n",
    "print(f\"Pasta base: {PASTA_BASE}\")\n",
    "print(f\"Pasta entrada: {PASTA_ENTRADA}\")\n",
    "print(f\"Pasta saída: {PASTA_SAIDA}\")\n",
    "print(f\"Pasta modelos: {PASTA_MODELOS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WrrHt09xnCyU"
   },
   "outputs": [],
   "source": [
    "def treinar_e_salvar_modelo():\n",
    "    training_dfs = []\n",
    "\n",
    "    # Iterar sobre todos os arquivos na PASTA_ENTRADA\n",
    "    for f in os.listdir(PASTA_ENTRADA):\n",
    "        caminho_arquivo = os.path.join(PASTA_ENTRADA, f)\n",
    "        nome_base, extensao = os.path.splitext(f)\n",
    "\n",
    "        # Verificar se é um arquivo válido para treinamento\n",
    "        # Removida a exclusão explícita de ARQUIVO_TREINO para que ele seja incluído no loop\n",
    "        if (os.path.isfile(caminho_arquivo) and\n",
    "            extensao.lower() in EXTENSOES_VALIDAS and\n",
    "            \"_classificado\" not in nome_base):\n",
    "\n",
    "            print(f\"Tentando carregar arquivo para treino: {caminho_arquivo}\")\n",
    "            temp_df = None\n",
    "            try:\n",
    "                if extensao.lower() == \".csv\":\n",
    "                    try:\n",
    "                        temp_df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "                    except Exception:\n",
    "                        temp_df = pd.read_csv(caminho_arquivo, sep=',')\n",
    "                elif extensao.lower() == \".xlsx\":\n",
    "                    temp_df = pd.read_excel(caminho_arquivo)\n",
    "\n",
    "                if temp_df is not None:\n",
    "                    # Verificar se as colunas necessárias existem\n",
    "                    if COLUNA_TEXTO not in temp_df.columns or COLUNA_LABEL not in temp_df.columns:\n",
    "                        print(f\"⚠️ Aviso: Arquivo '{f}' não contém as colunas '{COLUNA_TEXTO}' e/ou '{COLUNA_LABEL}'. Pulando este arquivo.\")\n",
    "                        continue\n",
    "\n",
    "                    training_dfs.append(temp_df)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erro ao carregar o arquivo '{f}': {e}. Pulando este arquivo.\")\n",
    "                continue\n",
    "\n",
    "    # Combinar todos os DataFrames carregados\n",
    "    if not training_dfs:\n",
    "        print(\"❌ Erro: Nenhum arquivo de treino válido encontrado ou carregado. Não é possível treinar o modelo.\")\n",
    "        return\n",
    "\n",
    "    df_train = pd.concat(training_dfs, ignore_index=True)\n",
    "\n",
    "    if df_train.empty:\n",
    "        print(\"❌ Erro: DataFrame de treino resultante está vazio. Não é possível treinar o modelo.\")\n",
    "        return\n",
    "\n",
    "    df_train[COLUNA_TEXTO] = df_train[COLUNA_TEXTO].fillna(\"\")\n",
    "\n",
    "    # Processar a coluna de rótulo para considerar 'x' como 1 e outros como 0\n",
    "    df_train[COLUNA_LABEL] = df_train[COLUNA_LABEL].astype(str).str.strip().str.lower().apply(\n",
    "        lambda val: 1 if val == \"x\" else 0\n",
    "    )\n",
    "    df_train[COLUNA_LABEL] = df_train[COLUNA_LABEL].astype(int)\n",
    "\n",
    "    # Vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_df=0.95\n",
    "    )\n",
    "\n",
    "    X_train = vectorizer.fit_transform(df_train[COLUNA_TEXTO])\n",
    "    y_train = df_train[COLUNA_LABEL]\n",
    "\n",
    "    # --- Adicionado para depuração: verificar a distribuição das classes após o processamento ---\n",
    "    print(\"Distribuição das classes na coluna '{}' após processamento:\".format(COLUNA_LABEL))\n",
    "    print(y_train.value_counts())\n",
    "    # --------------------------------------------------------------------------------------\n",
    "\n",
    "    # Modelo\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Salvar artefatos\n",
    "    joblib.dump(vectorizer, ARQ_VECTORIZER)\n",
    "    joblib.dump(model, ARQ_MODEL)\n",
    "\n",
    "    print(\"✔ Modelo treinado e salvo\")\n",
    "    print(ARQ_VECTORIZER)\n",
    "    print(ARQ_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12076,
     "status": "ok",
     "timestamp": 1768523533460,
     "user": {
      "displayName": "Arthur Santos",
      "userId": "03203688616351214794"
     },
     "user_tz": 180
    },
    "id": "25c5b6b5",
    "outputId": "e13b883a-2fa4-4560-c347-20d4ce665541"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando carregar arquivo para treino: /content/drive/MyDrive/teste_marcacao/revisar/dados_treino.csv\n",
      "Distribuição das classes na coluna 'excluir' após processamento:\n",
      "excluir\n",
      "1    711\n",
      "0    371\n",
      "Name: count, dtype: int64\n",
      "✔ Modelo treinado e salvo\n",
      "/content/drive/MyDrive/teste_marcacao/revisar/vectorizer.joblib\n",
      "/content/drive/MyDrive/teste_marcacao/revisar/model.joblib\n"
     ]
    }
   ],
   "source": [
    "treinar_e_salvar_modelo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5cl_gL_UnD6k"
   },
   "outputs": [],
   "source": [
    "def carregar_modelo():\n",
    "    if not os.path.exists(ARQ_VECTORIZER) or not os.path.exists(ARQ_MODEL):\n",
    "        raise FileNotFoundError(\"Vectorizer/Model não encontrados. Rode o BLOCO 3 primeiro.\")\n",
    "\n",
    "    vectorizer = joblib.load(ARQ_VECTORIZER)\n",
    "    model = joblib.load(ARQ_MODEL)\n",
    "    return vectorizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s8ipxlOanFEM"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classificar_arquivo(caminho_arquivo, vectorizer, model):\n",
    "    nome_base, extensao = os.path.splitext(os.path.basename(caminho_arquivo))\n",
    "\n",
    "    # Carregar dados\n",
    "    if extensao == \".csv\":\n",
    "        try:\n",
    "            df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler CSV com ponto e vírgula: {e}. Tentando com vírgula...\")\n",
    "            df = pd.read_csv(caminho_arquivo, sep=',')\n",
    "    else:\n",
    "        df = pd.read_excel(caminho_arquivo)\n",
    "\n",
    "    # Verificar se a COLUNA_TEXTO existe\n",
    "    if COLUNA_TEXTO not in df.columns:\n",
    "        print(f\"Erro: O arquivo '{caminho_arquivo}' não possui a coluna '{COLUNA_TEXTO}'. Colunas disponíveis: {df.columns.tolist()}\")\n",
    "        raise KeyError(f\"Coluna '{COLUNA_TEXTO}' não encontrada no arquivo '{caminho_arquivo}'.\")\n",
    "\n",
    "    df[COLUNA_TEXTO] = df[COLUNA_TEXTO].fillna(\"\")\n",
    "\n",
    "    # Remover caracteres ilegais para XML/Excel\n",
    "    illegal_char_re = re.compile(r'[\\x00-\\x08\\x0b-\\x0c\\x0e-\\x1f]')\n",
    "    df[COLUNA_TEXTO] = df[COLUNA_TEXTO].apply(lambda x: illegal_char_re.sub('', x) if isinstance(x, str) else x)\n",
    "\n",
    "    # Vetorização\n",
    "    X = vectorizer.transform(df[COLUNA_TEXTO])\n",
    "\n",
    "    # Predições\n",
    "    probas = model.predict_proba(X)[:, 1]\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    df[\"prob_X\"] = probas\n",
    "    df[\"marcacao_X\"] = pd.Series(preds).map({1: \"x\", 0: \"\"})\n",
    "\n",
    "    # Revisão humana - Lógica invertida para CONFIANTE e DESCARTADO\n",
    "    df[\"status_revisao\"] = df[\"prob_X\"].apply(\n",
    "        lambda p:\n",
    "            (\n",
    "                \"DESCARTADO\" if p >= LIMIAR_CONFIANTE else  # Se alta probabilidade de ser 'X' (excluir), marca como DESCARTADO\n",
    "                \"REVISAR\" if p >= LIMIAR_DUVIDOSO else      # Se probabilidade intermediária, marca como REVISAR\n",
    "                \"CONFIANTE\"                                 # Se baixa probabilidade de ser 'X' (não excluir), marca como CONFIANTE\n",
    "            )\n",
    "    )\n",
    "\n",
    "    # Versionamento\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Cria subpasta para o arquivo se não existir\n",
    "    pasta_arquivo = os.path.join(PASTA_SAIDA, nome_base)\n",
    "    os.makedirs(pasta_arquivo, exist_ok=True)\n",
    "\n",
    "    saida = os.path.join(\n",
    "        pasta_arquivo,\n",
    "        f\"{nome_base}_classificado_{timestamp}.xlsx\"\n",
    "    )\n",
    "\n",
    "    df.to_excel(saida, index=False)\n",
    "    return saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgIwXMXKotmv"
   },
   "outputs": [],
   "source": [
    "def classificar_pasta():\n",
    "    vectorizer, model = carregar_modelo()\n",
    "\n",
    "    arquivos = [\n",
    "        f for f in os.listdir(PASTA_ENTRADA)\n",
    "        if f.endswith(EXTENSOES_VALIDAS)\n",
    "        and not f.endswith(\"_classificado.xlsx\")\n",
    "        and os.path.join(PASTA_ENTRADA, f) != ARQUIVO_TREINO  # Excluir o arquivo de treino\n",
    "    ]\n",
    "\n",
    "    if not arquivos:\n",
    "        print(\"Nenhum arquivo para classificar.\")\n",
    "        return\n",
    "\n",
    "    saidas = []\n",
    "    for f in arquivos:\n",
    "        caminho = os.path.join(PASTA_ENTRADA, f)\n",
    "        print(f\"Tentando classificar arquivo: {caminho}\") # Adicionado para depuração\n",
    "        try:\n",
    "            saida = classificar_arquivo(caminho, vectorizer, model)\n",
    "            saidas.append(saida)\n",
    "        except (KeyError, pd.errors.ParserError) as e:\n",
    "            print(f\"❌ Erro ao classificar o arquivo {caminho}: {e}. Pulando este arquivo.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Ocorreu um erro inesperado ao classificar o arquivo {caminho}: {e}. Pulando este arquivo.\")\n",
    "\n",
    "    print(\"✔ Classificação em lote concluída\")\n",
    "    for s in saidas:\n",
    "        print(\"Gerado:\", s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1768523534685,
     "user": {
      "displayName": "Arthur Santos",
      "userId": "03203688616351214794"
     },
     "user_tz": 180
    },
    "id": "7d79f08b",
    "outputId": "9a64ac01-0fdb-4d35-b38f-eafb6d3d0237"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conteúdo da pasta '/content/drive/MyDrive/teste_marcacao/revisar/':\n",
      "  - dados_treino.csv\n",
      "  - conteudo_lote_17_unificado_classificado_20260113_232900.xlsx\n",
      "  - conteudo_lote_17_unificado (1)_classificado_20260113_232904.xlsx\n",
      "  - conteudo_lote_18_unificado_classificado_20260113_232907.xlsx\n",
      "  - conteudo_lote_21_unificado_classificado_20260113_232910.xlsx\n",
      "  - conteudo_lote_20_unificado_classificado_20260113_232912.xlsx\n",
      "  - conteudo_lote_19_unificado_classificado_20260113_232914.xlsx\n",
      "  - conteudo_lote_15_unificado_classificado_20260113_232917.xlsx\n",
      "  - conteudo_lote_16_unificado_classificado_20260113_232921.xlsx\n",
      "  - conteudo_lote_0406_unificado_classificado_20260113_232928.xlsx\n",
      "  - conteudo_lote_24_unificado_classificado_20260113_232933.xlsx\n",
      "  - conteudo_lote_25_unificado_classificado_20260113_232936.xlsx\n",
      "  - conteudo_lote_0710_unificado_classificado_20260113_232949.xlsx\n",
      "  - conteudo_lote_1114_unificado_classificado_20260113_233006.xlsx\n",
      "  - conteudo_lote_22_unificado_classificado_20260113_233014.xlsx\n",
      "  - conteudo_lote_23_unificado_classificado_20260113_233018.xlsx\n",
      "  - vectorizer.joblib\n",
      "  - model.joblib\n",
      "  - resultados\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(f\"Conteúdo da pasta entrada '{PASTA_ENTRADA}':\")\n",
    "conteudo_pasta = os.listdir(PASTA_ENTRADA) if os.path.exists(PASTA_ENTRADA) else []\n",
    "if not conteudo_pasta:\n",
    "    print(\"  (Vazio)\")\n",
    "else:\n",
    "    for item in conteudo_pasta:\n",
    "        print(f\"  - {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88821,
     "status": "ok",
     "timestamp": 1768523623501,
     "user": {
      "displayName": "Arthur Santos",
      "userId": "03203688616351214794"
     },
     "user_tz": 180
    },
    "id": "oSMH7m7SsoZo",
    "outputId": "25dbde7e-a176-4154-fd48-a41ed8b373c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_17_unificado_classificado_20260113_232900.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_17_unificado (1)_classificado_20260113_232904.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_18_unificado_classificado_20260113_232907.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_21_unificado_classificado_20260113_232910.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_20_unificado_classificado_20260113_232912.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_19_unificado_classificado_20260113_232914.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_15_unificado_classificado_20260113_232917.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_16_unificado_classificado_20260113_232921.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_0406_unificado_classificado_20260113_232928.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_24_unificado_classificado_20260113_232933.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_25_unificado_classificado_20260113_232936.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_0710_unificado_classificado_20260113_232949.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_1114_unificado_classificado_20260113_233006.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_22_unificado_classificado_20260113_233014.xlsx\n",
      "Tentando classificar arquivo: /content/drive/MyDrive/teste_marcacao/revisar/conteudo_lote_23_unificado_classificado_20260113_233018.xlsx\n",
      "✔ Classificação em lote concluída\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_17_unificado_classificado_20260113_232900_classificado_20260116_003220.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_17_unificado (1)_classificado_20260113_232904_classificado_20260116_003225.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_18_unificado_classificado_20260113_232907_classificado_20260116_003230.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_21_unificado_classificado_20260113_232910_classificado_20260116_003232.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_20_unificado_classificado_20260113_232912_classificado_20260116_003234.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_19_unificado_classificado_20260113_232914_classificado_20260116_003236.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_15_unificado_classificado_20260113_232917_classificado_20260116_003240.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_16_unificado_classificado_20260113_232921_classificado_20260116_003245.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_0406_unificado_classificado_20260113_232928_classificado_20260116_003251.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_24_unificado_classificado_20260113_232933_classificado_20260116_003258.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_25_unificado_classificado_20260113_232936_classificado_20260116_003301.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_0710_unificado_classificado_20260113_232949_classificado_20260116_003314.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_1114_unificado_classificado_20260113_233006_classificado_20260116_003332.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_22_unificado_classificado_20260113_233014_classificado_20260116_003342.xlsx\n",
      "Gerado: /content/drive/MyDrive/teste_marcacao/revisar/resultados/conteudo_lote_23_unificado_classificado_20260113_233018_classificado_20260116_003346.xlsx\n"
     ]
    }
   ],
   "source": [
    "classificar_pasta()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOYXmkDNtSnlWIoLxxN2TqI",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
